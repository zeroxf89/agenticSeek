<p align="center">
<img align="center" src="./media/whale_readme.jpg">
<p>

--------------------------------------------------------------------------------
[English](./README.md) | [ç¹é«”ä¸­æ–‡](./README_CHT.md) | [æ—¥æœ¬èªž](./README_JP.md) | FranÃ§ais

# AgenticSeek: Une IA comme Manus mais Ã  base d'agents DeepSeek R1 fonctionnant en local.

Une alternative **entiÃ¨rement locale** Ã  Manus AI, un assistant IA qui code, explore votre systÃ¨me de fichiers, navigue sur le web et corrige ses erreurs, tout cela sans envoyer la moindre donnÃ©e dans le cloud. Cet agent autonome fonctionne entiÃ¨rement sur votre hardware, garantissant la confidentialitÃ© de vos donnÃ©es.

[![Visit AgenticSeek](https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square)](https://fosowl.github.io/agenticSeek.html) ![License](https://img.shields.io/badge/license-GPL--3.0-green) [![Discord](https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white)](https://discord.gg/8hGDaME3TC) [![Twitter](https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl)](https://x.com/Martin993886460)

> ðŸ› ï¸ **En cours de dÃ©veloppement** â€“ On cherche activement des contributeurs!

https://github.com/user-attachments/assets/4bd5faf6-459f-4f94-bd1d-238c4b331469

> *Recherche sur le web des activitÃ©s Ã  faire Ã  Paris*

> *Code le jeu snake en python*

> *J'aimerais que tu trouve une api mÃ©tÃ©o et que tu me code une application qui affiche la mÃ©tÃ©o Ã  Toulouse*



## FonctionnalitÃ©s:

- **100% Local**: Fonctionne en local sur votre PC. Vos donnÃ©es restent les vÃ´tres. 

- **AccÃ¨s Ã  vos Fichiers**: Utilise bash pour naviguer et manipuler vos fichiers.

- **Codage semi-autonome**: Peut Ã©crire, dÃ©boguer et exÃ©cuter du code en Python, C, Golang et d'autres langages Ã  venir. 

- **Routage d'Agent**: SÃ©lectionne automatiquement lâ€™agent appropriÃ© pour la tÃ¢che. 

- **Planification**: Pour les taches complexe utilise plusieurs agents.

- **Navigation Web Autonome**: Navigation web autonome.

- **Memoire efficace**: Gestion efficace de la mÃ©moire et des sessions. 

---

## **Installation**

Assurez-vous dâ€™avoir installÃ© le pilote Chrome, Docker et Python 3.10.

Nous vous conseillons fortement d'utiliser exactement Python 3.10 pour l'installation. Des erreurs de dÃ©pendances pourraient survenir autrement.

Pour les problÃ¨mes liÃ©s au pilote Chrome, consultez la section Chromedriver.

### 1ï¸âƒ£ Cloner le repo et configurer

```sh
git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
```

### 2 **CrÃ©er un environnement virtuel**

```sh
python3 -m venv agentic_seek_env
source agentic_seek_env/bin/activate     
# Sur Windows: agentic_seek_env\Scripts\activate
```

### 3ï¸âƒ£ **Installation**

**Automatique:**

```sh
./install.sh
```

**Manuel:**

**Note : Pour tous les systÃ¨mes d'exploitation, assurez-vous que le ChromeDriver que vous installez correspond Ã  la version de Chrome installÃ©e. ExÃ©cutez `google-chrome --version`. Consultez les problÃ¨mes connus si vous avez Chrome >135**

- *Linux*:

Mettre Ã  jour la liste des paquets : `sudo apt update`

Installer les dÃ©pendances : `sudo apt install -y alsa-utils portaudio19-dev python3-pyaudio libgtk-3-dev libnotify-dev libgconf-2-4 libnss3 libxss1`

Installer ChromeDriver correspondant Ã  la version de votre navigateur Chrome :
`sudo apt install -y chromium-chromedriver`

Installer les prÃ©requis : `pip3 install -r requirements.txt`

- *macOS*:

Mettre Ã  jour brew : `brew update`

Installer chromedriver : `brew install --cask chromedriver`

Installer portaudio : `brew install portaudio`

Mettre Ã  jour pip : `python3 -m pip install --upgrade pip`

Mettre Ã  jour wheel : `pip3 install --upgrade setuptools wheel`

Installer les prÃ©requis : `pip3 install -r requirements.txt`

- *Windows*:

Installer pyreadline3 : `pip install pyreadline3`

Installer portaudio manuellement (par exemple, via vcpkg ou des binaires prÃ©compilÃ©s) puis exÃ©cutez : `pip install pyaudio`

TÃ©lÃ©charger et installer chromedriver manuellement depuis : https://sites.google.com/chromium.org/driver/getting-started

Placez chromedriver dans un rÃ©pertoire inclus dans votre PATH.

Installer les prÃ©requis : `pip3 install -r requirements.txt`


## Faire fonctionner sur votre machine 

**Nous recommandons dâ€™utiliser au minimum DeepSeek 14B, les modÃ¨les plus petits ont du mal avec lâ€™utilisation des outils et oublient rapidement le contexte.**

Lancer votre provider local, par exemple avec ollama:
```sh
ollama serve
```

**Configurer le config.ini**

Modifiez le fichier config.ini pour dÃ©finir provider_name sur un fournisseur supportÃ© et provider_model sur un LLM compatible avec votre fournisseur. Nous recommandons des modÃ¨les de raisonnement comme *Qwen* ou *Deepseek*.

Consultez la section **FAQ** Ã  la fin du README pour connaÃ®tre le matÃ©riel requis.

```sh
[MAIN]
is_local = True # Si vous exÃ©cutez localement ou avec un fournisseur distant.
provider_name = ollama # ou lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choisissez un modÃ¨le adaptÃ© Ã  votre matÃ©riel
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # nom de votre IA
recover_last_session = True # rÃ©cupÃ©rer ou non la session prÃ©cÃ©dente
save_session = True # mÃ©moriser ou non la session actuelle
speak = True # synthÃ¨se vocale
listen = False # reconnaissance vocale, uniquement pour CLI
work_dir =  /Users/mlg/Documents/workspace # L'espace de travail pour AgenticSeek.
jarvis_personality = False # Utiliser une personnalitÃ© plus "Jarvis", non recommandÃ© avec des petits modÃ¨les
languages = en fr # Liste des langages, la synthÃ¨se vocale utilisera par dÃ©faut la premiÃ¨re langue de la liste
[BROWSER]
headless_browser = True # Utiliser ou non le navigateur sans interface graphique, recommandÃ© uniquement avec l'interface web.
stealth_mode = True # Utiliser selenium non dÃ©tectable pour rÃ©duire la dÃ©tection du navigateur
```

Remarque : Certains fournisseurs (ex : lm-studio) nÃ©cessitent `http://` devant l'adresse IP. Par exemple `http://127.0.0.1:1234`



**Liste des provideurs locaux**

| Fournisseur | Local ? | Description                                               |
|-------------|---------|-----------------------------------------------------------|
| ollama      | Oui     | ExÃ©cutez des LLM localement avec facilitÃ© en utilisant ollama comme fournisseur LLM |
| lm-studio   | Oui     | ExÃ©cutez un LLM localement avec LM studio (dÃ©finissez `provider_name` sur `lm-studio`) |
| openai      | Oui     | Utilisez une API local compatible avec openai |


### **DÃ©marrer les services & ExÃ©cuter**

Activez votre environnement Python si nÃ©cessaire.
```sh
source agentic_seek_env/bin/activate
```

DÃ©marrez les services requis. Cela lancera tous les services dÃ©finis dans le fichier docker-compose.yml, y compris :
    - searxng
    - redis (nÃ©cessaire pour searxng)
    - frontend

```sh
sudo ./start_services.sh # MacOS
start ./start_services.cmd # Windows
```

**Option 1 :** ExÃ©cuter avec l'interface CLI.

```sh
python3 cli.py
```

**Option 2 :** ExÃ©cuter avec l'interface Web.

DÃ©marrez le backend.

```sh
python3 api.py
```

Allez sur `http://localhost:3000/` et vous devriez voir l'interface web.

Veuillez noter que l'interface web ne diffuse pas les messages en continu pour le moment.


Voyez la section **Utilisation** si vous ne comprenez pas comment lâ€™utiliser

Voyez la section **ProblÃ¨mes** connus si vous rencontrez des problÃ¨mes

Voyez la section **ExÃ©cuter avec une API** si votre matÃ©riel ne peut pas exÃ©cuter DeepSeek localement

Voyez la section **Configuration** pour une explication dÃ©taillÃ©e du fichier de configuration.

---

## Utilisation

Assurez-vous que les services sont en cours dâ€™exÃ©cution avec ./start_services.sh et lancez AgenticSeek avec le CLI ou l'interface Web.

**CLI:**
Vous verrez un prompt : ">>> "  
Cela indique quâ€™AgenticSeek attend que vous saisissiez des instructions.  
Vous pouvez Ã©galement utiliser la reconnaissance vocale en dÃ©finissant `listen = True` dans la configuration.  
Pour quitter, dites simplement `goodbye`.  

**Interface:**

Assurez-vous d'avoir bien dÃ©marrÃ© le backend avec `python3 api.py`.  
Allez sur `localhost:3000` oÃ¹ vous verrez une interface web.  
Tapez simplement votre message et patientez.  
Si vous n'avez pas d'interface sur `localhost:3000`, c'est que vous n'avez pas dÃ©marrÃ© les services avec `start_services.sh`.

Voici quelques exemples dâ€™utilisation :

### Programmation

> *Aide-moi avec la multiplication de matrices en Golang*

> *Initalize un nouveau project python, setup le readme, gitignore etc.. et fait un premier commit*

> *Fais un jeu snake en Python*

### Recherche web

> *Fais une recherche sur le web pour trouver des startups technologiques au Japon qui travaillent sur des recherches avancÃ©es en IA*

> *Peux-tu trouver sur internet qui a crÃ©Ã© agenticSeek ?*

> *Peux-tu trouver sur quel site je peux acheter une RTX 4090 Ã  bas prix ?*

### Fichier

> *HÃ©, peux-tu trouver oÃ¹ est contrat.pdf ? Je lâ€™ai perdu*

> *Montre-moi combien dâ€™espace il me reste sur mon disque*

> *Trouve et lis le fichier README.md et suis les instructions dâ€™installation*

### Conversation

> *Parle-moi de la France*

> *Quel est le sens de la vie ?*

> *Donne moi une recette simple pour ce midi j'ai pas d'inspi*

AprÃ¨s avoir saisi votre requÃªte, AgenticSeek attribuera le meilleur agent pour la tÃ¢che.

Le systÃ¨me de routage des agents peut parfois ne pas toujours attribuer le bon agent en fonction de votre requÃªte.

Par consÃ©quent, vous devez Ãªtre assez explicite sur ce que vous voulez et sur la maniÃ¨re dont lâ€™IA doit procÃ©der. Par exemple, si vous voulez quâ€™elle effectue une recherche sur le web, ne dites pas :

Connait-tu de bons pays pour voyager seul ?

Dites plutÃ´t :

Fait une recherche sur le web, quels sont les meilleurs pays pour voyager seul?

---

## **ExÃ©cuter le LLM sur votre propre serveur**  

Si vous disposez dâ€™un ordinateur puissant ou dâ€™un serveur que vous voulez utiliser, mais que vous souhaitez y accÃ©der depuis votre ordinateur portable, vous avez la possibilitÃ© dâ€™exÃ©cuter le LLM sur un serveur distant.

### 1ï¸âƒ£  **Configurer et dÃ©marrer les scripts du serveur** 

Sur votre "serveur" qui exÃ©cutera le modÃ¨le IA, obtenez lâ€™adresse IP

```sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1
```

Remarque : Pour Windows ou macOS, utilisez respectivement ipconfig ou ifconfig pour trouver lâ€™adresse IP.

Clonez le dÃ©pÃ´t et entrez dans le dossier server/.


```sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/server/
```

Installez les dÃ©pendances spÃ©cifiques au serveur :

```sh
pip3 install -r requirements.txt
```

ExÃ©cutez le script du serveur.

```sh
python3 app.py --provider ollama --port 3333
```

Vous avez le choix entre utiliser ollama et llamacpp comme service LLM.

### 2ï¸âƒ£ **Lancer** 

Maintenant, sur votre ordinateur personnel :

Modifiez le fichier config.ini pour dÃ©finir provider_name sur server et provider_model sur deepseek-r1:14b.

DÃ©finissez provider_server_address sur lâ€™adresse IP de la machine qui exÃ©cutera le modÃ¨le.

```sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:14b
provider_server_address = x.x.x.x:3333
```

Ensuite, exÃ©cutez avec le CLI ou l'interface graphique comme expliquÃ© dans la section pour les fournisseurs locaux.

## **ExÃ©cuter avec une API externe**  

AVERTISSEMENT : Assurez-vous quâ€™il nâ€™y a pas dâ€™espace en fin de ligne dans la configuration.

```sh
[MAIN]
is_local = False
provider_name = openai
provider_model = gpt-4o
provider_server_address = 127.0.0.1:5000 # n'importe pas
```

**Liste de provideurs API**
| Fournisseur  | Local ? | Description                                               |
|--------------|---------|-----------------------------------------------------------|
| openai       | Non  | Utilise l'API ChatGPT                                     |
| deepseek-api | Non     | API Deepseek (non privÃ©)                                  |
| huggingface  | Non     | API Hugging-Face (non privÃ©)                              |
| togetherAI   | Non     | Utilise l'API Together AI (non privÃ©)                     |
| google       | Non     | Utilise l'API Google Gemini (non privÃ©)                  |

Ensuite, exÃ©cutez avec le CLI ou l'interface graphique comme expliquÃ© dans la section pour les fournisseurs locaux.

## Config

Exemple de configuration :
```
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:1.5b
provider_server_address = 127.0.0.1:11434
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False
work_dir =  /Users/mlg/Documents/ai_folder
jarvis_personality = False
languages = en fr
[BROWSER]
headless_browser = False
stealth_mode = False
```

**Explication du fichier config.ini**:

`is_local` -> ExÃ©cute lâ€™agent localement (True) ou sur un serveur distant (False).

`provider_name` -> Le fournisseur Ã  utiliser (parmi : ollama, server, lm-studio, deepseek-api).

`provider_model` -> Le modÃ¨le utilisÃ©, par exemple, deepseek-r1:1.5b.

`provider_server_address` -> Adresse du serveur, par exemple, 127.0.0.1:11434 pour local. DÃ©finissez nâ€™importe quoi pour une API non locale.

`agent_name` -> Nom de lâ€™agent, par exemple, Friday. UtilisÃ© comme mot dÃ©clencheur pour la reconnaissance vocale.

`recover_last_session` -> Reprend la derniÃ¨re session (True) ou non (False).

`save_session` -> Sauvegarde les donnÃ©es de la session (True) ou non (False).

`speak` -> Active la sortie vocale (True) ou non (False).

`listen` -> Ã‰coute les entrÃ©es vocales (True) ou non (False).

`work_dir` -> Dossier auquel lâ€™IA aura accÃ¨s, par exemple : /Users/user/Documents/.

`jarvis_personality` -> Utilise une personnalitÃ© inspirÃ© de Jarvis (True) ou non (False). Cela utilise simplement une prompt alternative. Marche moins bien en franÃ§ais.

`headless_browser` -> ExÃ©cute le navigateur sans fenÃªtre visible (True) ou non (False).

`stealth_mode` -> Rend la dÃ©tection des bots plus difficile. Le seul inconvÃ©nient est que vous devez installer manuellement lâ€™extension anticaptcha.

`languages` -> La liste de languages supportÃ©s (nÃ©cessaire pour le routage d'agents). Plus la liste est longue. Plus un nombre important de modÃ¨les sera tÃ©lÃ©chargÃ©s.

## Providers

Le tableau ci-dessous montre les LLM providers disponibles :

| Provider  | Local? | Description                                               |
|-----------|--------|-----------------------------------------------------------|
| ollama    | Yes    | ExÃ©cutez des LLM localement avec facilitÃ© en utilisant Ollama comme fournisseur LLM 
| server    | Yes    | HÃ©bergez le modÃ¨le sur une autre machine, exÃ©cutez sur votre machine locale 
| lm-studio  | Yes    | ExÃ©cutez un LLM localement avec LM Studio (dÃ©finissez provider_name sur lm-studio) 
| openai    | No     | Utilise l'API ChatGPT (pas privÃ©) |
| deepseek-api  | No     | Utilise l'API Deepseek (pas privÃ©) |
| huggingface| No    | Utilise Hugging-Face (pas privÃ©) |
| together| No    | Utilise l'api Together AI |

Pour sÃ©lectionner un provider LLM, modifiez le config.ini :

```
is_local = False
provider_name = openai
provider_model = gpt-4o
provider_server_address = 127.0.0.1:5000
```

`is_local` : doit Ãªtre True pour tout LLM exÃ©cutÃ© localement, sinon False.

`provider_name` : SÃ©lectionnez le fournisseur Ã  utiliser par son nom, voir la liste des fournisseurs ci-dessus.

`provider_model` : DÃ©finissez le modÃ¨le Ã  utiliser par lâ€™agent.

`provider_server_address` : peut Ãªtre dÃ©fini sur nâ€™importe quoi si vous nâ€™utilisez pas le fournisseur server.

# ProblÃ¨mes connus 

## ProblÃ¨mes avec Chromedriver

Erreur #1:**incompatibilitÃ©**

`Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path`

Cela se produit sâ€™il y a une incompatibilitÃ© entre votre navigateur et la version de chromedriver.

Vous devez naviguer pour tÃ©lÃ©charger la derniÃ¨re version :

https://developer.chrome.com/docs/chromedriver/downloads

Si vous utilisez Chrome version 115 ou plus rÃ©cent, allez sur :

https://googlechromelabs.github.io/chrome-for-testing/

Et tÃ©lÃ©chargez la version de chromedriver correspondant Ã  votre systÃ¨me dâ€™exploitation.

![alt text](./media/chromedriver_readme.png)

Si cette section est incomplÃ¨te, merci de faire une nouvelle issue sur github.

## FAQ
**Q: Quel matÃ©riel est nÃ©cessaire ?**  

| Taille du ModÃ¨le  | GPU  | Commentaire                                               |
|--------------------|------|----------------------------------------------------------|
| 7B                | 8 Go VRAM | âš ï¸ Non recommandÃ©. Performances mÃ©diocres, hallucinations frÃ©quentes, et l'agent planificateur Ã©chouera probablement. |
| 14B               | 12 Go VRAM (par ex. RTX 3060) | âœ… Utilisable pour des tÃ¢ches simples. Peut rencontrer des difficultÃ©s avec la navigation web et les tÃ¢ches de planification. |
| 32B               | 24+ Go VRAM (par ex. RTX 4090) | ðŸš€ RÃ©ussite avec la plupart des tÃ¢ches, peut encore avoir des difficultÃ©s avec la planification des tÃ¢ches. |
| 70B+              | 48+ Go VRAM (par ex. Mac Studio) | ðŸ’ª Excellent. RecommandÃ© pour des cas d'utilisation avancÃ©s. |

**Q: Pourquoi deepseek et pas un autre modÃ¨le**  

DeepSeek R1 excelle dans le raisonnement et lâ€™utilisation dâ€™outils pour sa taille. Nous pensons que câ€™est un choix solide pour nos besoins, bien que dâ€™autres modÃ¨les fonctionnent Ã©galement (bien que moins bien pour un nombre Ã©quivalent de paramÃ¨tres).

**Q: J'ai une erreur quand je lance le programme, je fait quoi?**  

Assurez-vous quâ€™Ollama est en cours dâ€™exÃ©cution (ollama serve), que votre config.ini correspond Ã  votre fournisseur, et que les dÃ©pendances sont installÃ©es. Si cela ne fonctionne pas, nâ€™hÃ©sitez pas Ã  signaler un problÃ¨me.

**Q: C'est vraiment 100% local?**  

Oui, avec les fournisseurs Ollama, lm-studio ou Server, toute la reconnaissance vocale, le LLM et la synthÃ¨se vocale fonctionnent localement. Les options non locales (OpenAI ou autres API) sont facultatives.

**Q: En quoi c'est supÃ©rieur Ã  Manus**

Il ne l'est certainement pas, mais nous privilÃ©gions lâ€™exÃ©cution locale et la confidentialitÃ© par rapport Ã  une approche basÃ©e sur le cloud. Câ€™est une alternative plus accessible et surtout moins cher !

## Contribution

Nous recherchons des dÃ©veloppeurs pour amÃ©liorer AgenticSeek ! Consultez la section "issues" github ou les discussions.

[![Star History Chart](https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date)](https://www.star-history.com/#Fosowl/agenticSeek&Date)

[Guide du contributeur](./docs/CONTRIBUTING.md)

## Mainteneurs:
 > [Fosowl](https://github.com/Fosowl)
 > [steveh8758](https://github.com/steveh8758)
 > [https://github.com/antoineVIVIES](https://github.com/antoineVIVIES)
